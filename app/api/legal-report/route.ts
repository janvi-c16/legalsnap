import { db } from "@/config/db";
import { openai } from "@/config/OpenAiModel";
import { SessionChatTable } from "@/config/schema";
import { eq } from "drizzle-orm";
import { NextRequest, NextResponse } from "next/server";

const INDIAN_LEGAL_REPORT_PROMPT = `
You are an AI Legal Voice Agent assisting clients with legal issues under Indian law.

You just had a voice conversation with a user about a legal concern. Your task is to generate a **detailed legal session report** based on the conversation, **even if full information wasn't provided**. Use **Indian legal reasoning** and act references where necessary.

Output the report in the following strict JSON format:

{
  "sessionId": "string",
  "agent": "string",
  "user": "string",
  "timestamp": "ISO Date string",
  "legalIssue": "string",
  "summary": "string",
  "caseType": "string",
  "jurisdiction": "string",
  "urgency": "Low | Medium | High",
  "lawsDiscussed": ["law1", "law2"],
  "documentsMentioned": ["doc1", "doc2"],
  "recommendations": ["rec1", "rec2"]
}

### Guidelines:
- **Infer** missing fields using common Indian legal practices.
- Use Indian acts: IPC, CrPC, Indian Contract Act, Hindu Marriage Act, Rent Control Act, IT Act, etc.
- Example: If the issue is domestic violence, mention **Protection of Women from Domestic Violence Act, 2005** and **Section 498A IPC**.
- Use **district/city/state** for jurisdiction if available, else default to "India".
- If name is missing, set "Anonymous".
- Use professional tone and strictly valid JSON only â€” no explanations or markdown.
`;

// Default report template to use as fallback
const DEFAULT_REPORT = {
  sessionId: "",
  agent: "AI Legal Assistant",
  user: "Anonymous",
  timestamp: new Date().toISOString(),
  legalIssue: "General legal consultation",
  summary: "The user consulted about a legal matter. Detailed information was not available.",
  caseType: "General",
  jurisdiction: "India",
  urgency: "Medium",
  lawsDiscussed: ["Various Indian laws were discussed"],
  documentsMentioned: [],
  recommendations: ["Consult with a local lawyer for specific advice"]
};

export async function POST(req: NextRequest) {
  const { sessionId, sessionDetail, messages } = await req.json();

  try {
    // Validate input data
    if (!sessionId) {
      return NextResponse.json({ error: "Session ID is required" }, { status: 400 });
    }

    // Create a default report with the session ID
    const defaultReport = {
      ...DEFAULT_REPORT,
      sessionId: sessionId
    };

    // Even if no messages or session details, we'll still try to use the LLM
    // but prepare minimal context to work with
    const minimalMessages = !messages || !Array.isArray(messages) || messages.length === 0 ? 
      [{ role: "user", content: "I need legal advice" }] : messages;

    const userInput = "AI Indian Legal Assistant Info: " + JSON.stringify(sessionDetail || {}) + " . Conversation: " + JSON.stringify(minimalMessages);

    // Add more context to help the LLM generate a better report
    const enhancedPrompt = `${INDIAN_LEGAL_REPORT_PROMPT}

Even with limited information, please generate a detailed legal report. If specific details are missing, use reasonable assumptions based on the context provided. Focus on providing actionable legal advice that would be helpful to the user.`;

    const completion = await openai.chat.completions.create({
      model: "google/gemini-2.5-flash",
      messages: [
        { role: "system", content: enhancedPrompt },
        { role: "user", content: userInput }
      ],
    });

    const rawResp = completion.choices[0].message || "";
    //@ts-ignore
    const respContent = rawResp.content?.trim() || "";
    
    // Log the raw response for debugging
    console.log("Raw LLM response:", respContent);
    
    // Remove any markdown formatting and extract JSON
    const jsonRegex = /```(?:json)?([\s\S]*?)```|([\s\S]*)/;
    const match = respContent.match(jsonRegex);
    const extractedJson = (match[1] || match[2] || "").trim();
    
    let JSONResp;
    try {
      JSONResp = JSON.parse(extractedJson);
      
      // Ensure all required fields exist by merging with default report
      // but prioritize the LLM-generated fields
      JSONResp = {
        ...defaultReport,
        ...JSONResp,
        sessionId: sessionId, // Always use the provided sessionId
        // Add a flag to indicate this was generated by the LLM
        generatedByLLM: true
      };
    } catch (parseError) {
      console.error("Failed to parse model response:", parseError);
      console.error("Attempted to parse:", extractedJson);
      
      // Make another attempt with a more lenient approach
      try {
        // Try to extract anything that looks like JSON
        const jsonMatch = respContent.match(/{[\s\S]*}/);
        if (jsonMatch) {
          JSONResp = JSON.parse(jsonMatch[0]);
          JSONResp = {
            ...defaultReport,
            ...JSONResp,
            sessionId: sessionId,
            generatedByLLM: true,
            partialParse: true
          };
        } else {
          // Use default report if all parsing fails
          JSONResp = {
            ...defaultReport,
            parseError: "Failed to generate report from conversation",
            rawResponse: respContent.substring(0, 500) // Include part of the raw response for debugging
          };
        }
      } catch (secondError) {
        // Use default report if all parsing fails
        JSONResp = {
          ...defaultReport,
          parseError: "Failed to generate report from conversation",
          rawResponse: respContent.substring(0, 500) // Include part of the raw response for debugging
        };
      }
    }

    // Update the database with the report
    await db.update(SessionChatTable).set({
      report: JSONResp,
      conversation: messages
    }).where(eq(SessionChatTable.sessionId, sessionId));

    return NextResponse.json(JSONResp);
  } catch (e) {
    console.error("Error generating legal report:", e);
    
    // Create a more informative fallback report with the error
    const fallbackReport = {
      ...DEFAULT_REPORT,
      sessionId: sessionId || "",
      error: "Failed to generate report due to server error",
      errorDetails: e instanceof Error ? e.message : String(e),
      generatedByLLM: false,
      fallbackUsed: true
    };
    
    // Try to update the database with the fallback report
    try {
      if (sessionId) {
        await db.update(SessionChatTable).set({
          report: fallbackReport,
          conversation: minimalMessages || []
        }).where(eq(SessionChatTable.sessionId, sessionId));
      }
    } catch (dbError) {
      console.error("Failed to update database with fallback report:", dbError);
    }
    
    // Return the fallback report with an error flag for the frontend to handle
    return NextResponse.json({
      ...fallbackReport,
      error: "Could not generate legal report. Please try again later."
    });
  }
}
